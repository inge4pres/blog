<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>
    development - inge4pres
  </title><meta name="generator" content="Hugo 0.98.0" /><link
    rel="stylesheet"
    href="https://inge.4pr.es/css/styles.css"
    integrity=""
  />
  
  <script>
    
    if (window.matchMedia("(prefers-color-scheme: dark)").matches) {
      document.documentElement.classList.add("dark");
    } else {
      document.documentElement.classList.remove("dark");
    }
  </script>
  
</head>

  <body
    class="flex flex-col min-h-screen dark:bg-gray-900 dark:text-gray-100 transition-colors duration-500"
  ><header class="w-full px-4 pt-4 max-w-5xl mx-auto">
  <nav class="flex items-center justify-between flex-wrap">
    <div class="flex gap-2 items-center">
      
      <a href="mailto:fgualazzi@gmail.com" aria-label="EMail">
        <svg
          xmlns="http://www.w3.org/2000/svg"
          width="20"
          height="20"
          viewBox="0 0 24 24"
          stroke-width="1.5"
          stroke="currentColor"
          fill="none"
          stroke-linecap="round"
          stroke-linejoin="round"
        >
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <circle cx="12" cy="12" r="4" />
          <path d="M16 12v1.5a2.5 2.5 0 0 0 5 0v-1.5a9 9 0 1 0 -5.5 8.28" />
        </svg>
      </a>
      
      <a href="https://inge.4pr.es/" class="flex items-center font-bold">
        inge4pres
      </a>
    </div>

    <ul id="nav-menu" class="flex w-auto mt-0 space-x-2">
      
      <li>
        <a href="https://inge.4pr.es/about/" class="hover:text-blue-800 dark:hover:text-blue-300">You are what you is (F. Zappa)</a>
      </li>
      
      
      <li>
        <a href="https://inge.4pr.es/categories/blog/" class="hover:text-blue-800 dark:hover:text-blue-300">blog</a>
      </li>
      
    </ul>
  </nav>
</header>
<main class="flex-1 mx-4 md:mx-12 lg:mx-24 mt-8 sm:mt-16"> 
<article class="sm:mx-12 mb-16 prose lg:prose-lg">
  <h1><a href="https://inge.4pr.es/post/serverless-on-kubernetes/">Serverless on Kubernetes</a></h1>
  <p>Kubernetes is the <em>de facto</em> platform for running modern applications: its broad adoption in 2017 and the velocity of the project made it so and it&rsquo;s been accepted as the standard for many companies, from small to planet scale. It was impossible that such an extensible platform would be left out the serverless party, so here are the 4 main players offering FaaS to be run via k8s.</p>
<h3 id="a-premise">A premise</h3>
<p>If you&rsquo;re new to serverless and FaaS and all the previous buzzwords sound like cacophony to your ears, I really recommend reading <a href="https://martinfowler.com/articles/serverless.html">this post</a> and watching <a href="https://www.youtube.com/watch?v=LAWjdZYrUgI">this talk</a>. You could also notice how I put FaaS and serverless under the same hat here, this is just a personal opinion although some might argue that FaaS is a subset of serverless: historically I approached the serverless world using AWS Lambda, and I really tied the idea of writing functions and let someone else manage the infrastructure to the <em>serverless</em> concept. Also Sam Newman gave a <a href="https://youtu.be/CrS0HVQZiQI">good talk on serverless</a> that I really recommend watching.</p>
<h3 id="why-serverless-on-k8s">Why serverless on k8s</h3>
<p>It seems like a natural evolution for distributed systems to be composed by smaller and smaller parts. When moving from SOA to microservices the size of the service was reduced to enable development of more fine-grained functionalities into smaller and more maintainable components; taken to the extreme, you can reduce a microservice to be dedicated to just one task or to be  made of just one function, that&rsquo;s where FaaS fits into. Kubernetes is a great activator for such modularity as it creates a very powerful abstraction over infrastructure, so when developing a function as a separate module of a distributed system you can scale both vertically and horizontally any building block, each one independently from another, or you could even let Kubernetes manage that (think <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Pod Autoscaler</a>).</p>
<h3 id="four-players-offering-faas-on-k8s">Four players offering FaaS on k8s</h3>
<ul>
<li><a href="https://github.com/openfaas/faas">OpenFaaS</a></li>
<li><a href="https://github.com/fission/fission">Fission</a></li>
<li><a href="https://github.com/kubeless/kubeless">Kubeless</a></li>
<li><a href="https://github.com/fnproject/fn">Fn Project</a></li>
</ul>
<p>Now there might be others, but this 4 are the ones I mostly heard of in the last 6 months, so they must be the right ones üòÅ.</p>
<h4 id="comparison-criteria">Comparison criteria</h4>
<p>This is not a technical benchmark on the capabilities of this 4 frameworks: it&rsquo;s a <em>&ldquo;look Ma, I can serverless on k8s&rdquo;</em> post where I try and highlight the pros and cons of adopting one or the other; the criteria will be  installation methodology (client and server), languages support, cluster interoperability and developer experience, voted from 0 to 5 the higher the better.
I will use Kubernetes 1.8.6 that is, at the moment of writing, the latest available stable version.</p>
<p>The target function to deploy will be a super-serious analytics and business intelligence tool that will read the incoming HTTP request body and save it in a JSON document alongside with a timestamp. The JSON will be stored on a REDIS using a random UUIDv4 as key. All the code that will be deployed as functions is in <a href="https://github.com/inge4pres/blog/tree/master/serverless-on-kubernetes">Github</a>, while for installing the GCP cluster and REDIS I used the following</p>
<pre tabindex="0"><code>gcloud beta container --project &#34;${GCP_PROJECT}&#34; clusters create &#34;serverless-k8s&#34; \
  --zone &#34;europe-west2-c&#34; --username &#34;admin&#34; --cluster-version &#34;1.8.6-gke.0&#34; \
  --machine-type &#34;g1-small&#34; --image-type &#34;COS&#34; --disk-size &#34;50&#34; --num-nodes &#34;3&#34;

gcloud container clusters get-credentials serverless-k8s \
  --zone europe-west2-c --project &#34;${GCP_PROJECT}&#34;

helm init

helm install stable/redis
</code></pre><h4 id="fn-project">Fn Project</h4>
<h6 id="features">Features</h6>
<ul>
<li>function configuration via YAML</li>
<li>local development server via <code>fn start</code> and <code>fn run</code></li>
<li>uses DockerHub to store functions as containers</li>
<li>web UI with function monitoring</li>
</ul>
<h6 id="client-installation-4">Client installation: 4</h6>
<p>The <a href="https://github.com/fnproject/fn#install-cli-tool">installation instructions</a> are easy to read and execute, multiple platforms supported out of the box. User is required to set an environment variable with a DockerHub handle</p>
<pre tabindex="0"><code>export FN_REGISTRY=&lt;DOCKERHUB_USERNAME&gt;
</code></pre><h6 id="server-installation-3">Server installation: 3</h6>
<p>A Helm chart is provided under <a href="https://github.com/fnproject/fn-helm">fn-helm</a> but it&rsquo;s not immediately linked to the project&rsquo;s page. The installation requires the user to export an environment variable with the command</p>
<pre tabindex="0"><code>export FN_API_URL=http://$(kubectl get svc --namespace default fn-release-fn-api -o jsonpath=&#39;{.status.loadBalancer.ingress[0].ip}&#39;):80
</code></pre><h6 id="language-support-5">Language support: 5</h6>
<p>Built-in support for Java, Ruby, Go, Python. Runs any docker container as a function.</p>
<h6 id="cluster-interoperability-2">Cluster interoperability: 2</h6>
<p>It requires a LoadBalancer resource, so you won&rsquo;t be able to run it on <code>minikube</code> out of the box. It has MySQL and REDIS as dependency services and uses a <a href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/">DaemonSet</a> for the API controller, which might impact node&rsquo;s performance. No monitoring provided for the in-cluster components.</p>
<h6 id="developer-experience-3">Developer experience: 3</h6>
<p>Very extensive CLI interface. Functions are pipes: they should read Stdin and write to Stdout; some environment variables are injected to the running code to detect request URL and other configurations. I was able to complete my function deployment in roughly 1 hour after digging the docs a while to find out how to add custom configurations to the functions via environment variables.</p>
<h4 id="openfaas">OpenFaaS</h4>
<h6 id="features-1">Features</h6>
<ul>
<li>sponsored by CNCF</li>
<li>function grouping configuration via YAML (<a href="https://github.com/openfaas/faas-cli#use-a-yaml-stack-file">stack file</a>)</li>
<li>public function repository</li>
<li>Web UI with function monitoring</li>
<li>runs any docker container as a function</li>
</ul>
<h6 id="client-installation-2">Client installation: 2</h6>
<p>The <a href="https://github.com/openfaas/faas-cli#get-started-install-the-cli">CLI installation</a> is straight-forward for Linux and Mac users but it&rsquo;s not immediately available for Windows. I cannot find an easy way to set the cluster address to point the CLI to.</p>
<h6 id="server-installation-1">Server installation: 1</h6>
<p>Helm chart provided under <a href="https://github.com/openfaas/faas-netes/blob/master/HELM.md">faas-netes/helm</a> but it&rsquo;s failing the first time because of RBAC property not set and not rolling back, so I&rsquo;m forced to delete and recreate the release.
Even when installation is completed I cannot connect to the FaaS gateway as the service NodePort 31112, and the LoadBalancer creation errors out with</p>
<pre tabindex="0"><code>Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply
The Service &#34;gateway&#34; is invalid: spec.ports[0].nodePort: Invalid value: 31112: provided port is already allocated
</code></pre><h6 id="language-support-5-1">Language support: 5</h6>
<p>Built-in support for NodeJS, Ruby, Go, Python, C#, generic Dockerfile. Runs any docker container as a function.</p>
<h6 id="cluster-interoperability-4">Cluster interoperability: 4</h6>
<p>OpenFaas provides Prometheus monitoring with alerting out of the box, plus the architecture is very lean: just 2 pods that serve the API gateway and the function runner. Each function runs as a <code>Deployment</code> object and therefore can be scaled independently.</p>
<h6 id="developer-experience-2">Developer experience: 2</h6>
<p>After 2 hours trying to complete the setup on Kubernetes I&rsquo;m still not able to run any function on my cluster; I run a port-froward to the OpenFaaS gateway <code>kubectl port-forward gateway-pod-id 31112:8080</code> so I can run <code>faas-cli deploy -f samples.yml --gateway http://127.0.0.1:31112</code> inside the just cloned <code>faas-cli</code> repository and see some function in action.</p>
<h4 id="fission">Fission</h4>
<h6 id="features-2">Features</h6>
<ul>
<li>only 100ms function cold start (more on the topic <a href="https://serverless.com/blog/keep-your-lambdas-warm/">here</a>)</li>
<li>natively built for Kubernetes</li>
</ul>
<h6 id="client-installation-3">Client installation: 3</h6>
<p><a href="http://fission.io/docs/0.4.0/installation/#install-the-fission-cli">Guide</a> suggests to download a binary distribution via <code>curl</code> and place the binary¬ß under <code>/usr/local/bin</code>, very straightforward for Linux and OSX. Windows support is via WSL or using a binary <code>fission.exe</code> with download link provided. Some environment variables need to be setup to point to the cluster, but the <a href="http://fission.io/docs/0.4.0/installation/#cloud-setups">instructions</a> are very well written.</p>
<h6 id="server-installation-5">Server installation: 5</h6>
<p><a href="http://fission.io/docs/0.4.0/installation/#cloud-hosted-clusters-gke-aws-azure-etc">Also guide</a>: a single <code>helm</code> command installs all the components in a dedicated namespace <code>fission</code>.</p>
<h6 id="language-support-4">Language support: 4</h6>
<p>Built-in support for Linux binaries, Go, .NET, NodeJS, Perl, PHP 7, Python 3, Ruby as reported in the <a href="https://github.com/fission/fission#fission-concepts">concepts section</a>. Custom environment can be built and pushed to the cluster as containers.</p>
<h6 id="cluster-interoperability-2-1">Cluster interoperability: 2</h6>
<p>No monitoring at all and no UI provided to verify the functions state of execution or list, CLI is the only source of truth I can get and it&rsquo;s not easy to understand the architecture.</p>
<h6 id="developer-experience-2-1">Developer experience: 2</h6>
<p>Setup is very straightforward but then the development looks cumbersome (at least for Go): environment variables <a href="https://github.com/fission/fission/issues/356">cannot be set</a> yet, so this means hard-coded values in the code to connect to external services. Plus logging and function debugging is really hard, after 1 hour digging in documentation and trying to understand a cryptic <code>Internal server error (fission)</code> message, I am not able to run my Go function, and it&rsquo;s tough to tell why.</p>
<h4 id="kubeless">Kubeless</h4>
<h6 id="features-3">Features</h6>
<ul>
<li>natively built for kubernetes</li>
<li>web UI with function monitoring</li>
<li><a href="https://github.com/serverless/serverless-kubeless">serverless framework plugin</a> available</li>
</ul>
<h6 id="client-installation-5">Client installation: 5</h6>
<p>Binary distribution available for Linux, OSX and Windows in <a href="https://github.com/kubeless/kubeless/releases">Github release page</a>. No fuss, no hassle: download and run.</p>
<h6 id="server-installation-3-1">Server installation: 3</h6>
<p><a href="https://github.com/kubeless/kubeless#installation">Documentation</a> warns to create a namespace <code>kubeless</code> and use that. Same release page offers 3 options to install: Kubernetes with or without RBAC and Openshift. Applying the YAML with <code>kubectl apply -f kubeless-...</code> gets the server part up and running, but if I&rsquo;d like to install in a different namespace I would need to change the whole file. Providing a Helm chart is the standard Kubernetes packaging way so why not having one?</p>
<h6 id="language-support-3">Language support: 3</h6>
<p>Currently only Python, NodeJS, Ruby and .NET Core are supported. <a href="https://github.com/kubeless/kubeless/blob/master/docs/runtimes.md#custom-runtime-alpha">Custom runtimes</a> in the form of docker containers need to be built to run other languages, a feature in alpha which I&rsquo;m forced to explore to run my Go app.</p>
<h6 id="cluster-interoperability-4-1">Cluster interoperability: 4</h6>
<p>Monitoring provided via Prometheus integration; all backend services are run into dedicated namespace while functions are exposed using regular namespaces. It uses a StatefulSet to host Kafka and Zookeeper, they keep the functions state and there is a controller talking with Kubernetes API. I really like that it leverages Kubernetes-native primitives such as <code>ConfigMaps</code> and <code>Secrets</code> to manage function environment. It also uses a <code>CustomResourceDefinition</code> called <code>functions</code> so you can <code>kubectl get functions -o yaml</code>. What I don&rsquo;t like instead is the use of the cluster&rsquo;s etcd to store functions code when deploying from file.</p>
<h6 id="developer-experience-5">Developer experience: 5</h6>
<p>Everything worked great even when running an experimental feature such as custom environment: I was able to inject configuration via environment variables, get the function logs either via <code>kubeless</code> CLI or <code>kubectl</code> and debug my way out of the configuration error I put into my first image. Second deploy I did I was able to call my function and I validated the results connecting to REDIS afterwards.</p>
<h3 id="wrapping-up">Wrapping up</h3>
<p>There are lots of people investing in serverless right now, almost as many as there are for Kubernetes; the integrations between the two will bring a new exciting technology scenario in the next years. To my experience building this post none of the previously listed framework is ready for production usage, to be honest most of them are not even ready for the average developer weekend project usage. You need to know Kubernetes quite a bit to troubleshoot issues happening during deployment and/or execution of your functions and this makes the whole serverless idea crumble, as you&rsquo;ll be forced to dig into infrastructure details to have your code running.</p>
<p>If I&rsquo;d have to bet on one of the project I tried so far, I&rsquo;d do so on Kubeless; it&rsquo;s been definitely the smoothest setup  among all and the tight Kubernetes integration makes it a perfect candidate for community-driven growth. If you know any other framework that should be in this post please let me know it in the comments! I am always curious to see what&rsquo;s around in all things serverless so don&rsquo;t keep it for yourself!</p>

</article>

<article class="sm:mx-12 mb-16 prose lg:prose-lg">
  <h1><a href="https://inge.4pr.es/post/2017-10-28-golang-concurrency-pattern/">Golang Concurrency Patterns</a></h1>
  <p>In the early days of Go the language was often tailored towards &ldquo;system programming&rdquo; due to its C-stlye syntax and ability to write high-performance applications. Few time after, Go adoption was starting to gain traction for distributed systems development and projects like etcd, docker and kubernetes revealed the power of the networking capabilities offered by the internals in the language. Along the way a lot of libraries have been built around the powerful primitives offered by Go but in my opinion there is not enough use literature around the <em><a href="https://en.wikipedia.org/wiki/Communicating_sequential_processes">Communicating Sequential Processes</a></em> implementation available through channels and goroutines, they are not even widely used in the standard library. I&rsquo;ll detail here some concurrency patterns that I found useful and hopefully they&rsquo;ll be idiomatic enough to represent a good use case for you.</p>
<h5 id="a-premise">A premise</h5>
<p>CSP it&rsquo;s kind of a similar feature to threading but there are some differences; to know more on CSP I really recommend watching Rob Pike&rsquo;s <a href="https://vimeo.com/49718712">excellent talk on the topic</a>.</p>
<h4 id="my-experience">My experience</h4>
<p>Personally it took me a while to find my way out of the issues I ran into when first using concurrency features in Go: they are definitely the most complicated part of using Go, which is on average simpler that any other language I tried. So for me, the biggest problem was to understand what it means to have a goroutine spawned and how to control its execution or get data out of it, so I put together a list of examples on how concurrent programs flow can be controlled with the primitives built in the language.</p>
<h4 id="channel-channels-channels-everywhere">Channel, channels, channels everywhere</h4>
<p>A channel in Go is a way to pass messages between functions and goroutines, the official definition from <a href="https://tour.golang.org/concurrency/2">A Tour of Go</a> is:</p>
<p><em>Channels are a typed conduit through which you can send and receive values with the channel operator, <code>&lt;-</code></em></p>
<p>So what are they good for? They are actually not very helpful without goroutines: a goroutine is a lightweigth thread managed by the Go runtime (<a href="https://tour.golang.org/concurrency/1">definition</a>), think like a background process that can be spawned and does not need to be managed directly by you, I like the concept of <em>&ldquo;run and forget&rdquo;</em>.
The easiest concurrency pattern available is thinking of a goroutine processing some data in the background and returning them through a channel to the main thread executing our code; this can be very powerful and scale well to multiple functions and channels.</p>
<h4 id="waitgroups">WaitGroups</h4>
<p><a href="https://golang.org/pkg/sync/#WaitGroup">WaitGroups</a> are part of the <code>sync</code> package from the Go standard lib: they are a way for waiting the execution of goroutines to end properly and ensure all the work done in the background is completed. WaitGroups are often used with <code>defer</code> to fill in the wait queue when the goroutine exits.</p>
<h4 id="some-examples">Some examples</h4>
<p>For me the most difficult thing to understand when approaching concurrency was how to ensure all of my goroutines completed execution: to do this the easiest way is using WaitGroups as in <a href="https://github.com/inge4pres/blog/blob/master/golang-concurrency-patterns/waitgroup_test.go">waitgroup_test.go</a>: <code>wg.Add(1)</code> adds one item in the wait queue and <code>wg.Done()</code> removes one item from it; using <code>wg.Wait()</code> in the main process makes the process wait until the wait group is emptied.
If you run the tests with</p>
<pre tabindex="0"><code>go test -v . -race -run ^TestWaitGroup
</code></pre><p>you can see the execution time when using concurrency or not. Changing the value of <code>ops</code> variable in <a href="https://github.com/inge4pres/blog/blob/master/golang-concurrency-patterns/functions_test.go#L3">functions_test.go</a> will make the tests process less or more items.</p>
<p>With channels there are more features and gotchas that need to be taken into account:</p>
<ul>
<li>a read from a closed channel returns the type&rsquo;s zero-value</li>
<li>a send to a closed channel will <code>panic</code></li>
<li>a read and a send alone to an unbuffered channel are blocking: they will generate a deadlock if there is not a corresponding send/read operation on the other side of the channel</li>
<li>a send on a buffered channel will block when the buffer is full and no other read is happening on the other side</li>
</ul>
<p>That being said, there are a couple of notable usages that I like to include in my concurrency-enabled Go software: the <a href="https://github.com/inge4pres/blog/blob/master/golang-concurrency-patterns/channels_test.go#L22">fan-out pattern</a> where an input generates multiple goroutines that perform operations in the background and the output of the concurrent goroutines is fetched by a channel in the main thread. Another pattern is <a href="https://github.com/inge4pres/blog/blob/master/golang-concurrency-patterns/channels_test.go#L36">fan-in</a>: multiple functions can return values to a channel as long as the type is consistent. Run tests with</p>
<pre tabindex="0"><code>go test -v . -race -run ^TestChannelBuffered
</code></pre><p>to see fan-out/fan-in patterns in action.</p>
<p>Another interesting feature is powered by the <code>select</code> statement: you can read from multiple channels in the same function and define behavior for any given channel message, it is another sample of fan-in pattern. Using <code>select</code> will block until one of the send/receive operation is available, the operation gets chosen randomly if multiple are available at the same time. <code>select</code> has a similar syntax to <code>switch</code> so <code>case</code> and <code>default</code> are the scenario selector. Running <a href="https://github.com/inge4pres/blog/blob/master/golang-concurrency-patterns/channels_test.go#L55">multiple channels</a> lets you manage multiple types in a single point: run the test with</p>
<pre tabindex="0"><code>go test -v . -race -run ^TestMultipleChannelsSelect$
</code></pre><p>to check the execution of the multiple goroutines.</p>
<h4 id="conclusions">Conclusions</h4>
<p>My experience with Go concurrency primitives is still forming, I hope I can read and experiment more on the topic as it&rsquo;s one of Go&rsquo;s most powerful and at the same time less documented features! I&rsquo;d really love to hear feedback from the read so if you get up to this point, take a step forward and leave a comment below, I&rsquo;d really love to discuss.</p>
<h4 id="references">References</h4>
<ul>
<li><a href="https://gobyexample.com/worker-pools">Worker pools</a></li>
<li><a href="https://golangbot.com/channels/">Channels</a></li>
<li><a href="https://www.youtube.com/watch?v=yKQOunhhf4A">Concurrency made easy - Dave Cheney</a></li>
<li><a href="https://golang.org/doc/codewalk/sharemem/">Share memory by communicating - Codewalk</a></li>
<li><a href="http://www.jtolds.com/writing/2016/03/go-channels-are-bad-and-you-should-feel-bad/">Go channels are bad and you should feel bad</a></li>
</ul>

</article>

<article class="sm:mx-12 mb-16 prose lg:prose-lg">
  <h1><a href="https://inge.4pr.es/post/2017-10-01-getting-started-with-google-cloud-builder/">Getting Started With Google Cloud Builder</a></h1>
  <p>One of the advantages of containerized applications is the standardization, some would say &ldquo;write it once, runs everywhere&rdquo; but that&rsquo;s another motto for another product. Anyway with a new packaging technology the same problems are faced: build reproducibility, or the necessity for people doing Ops to know they are going to deploy the same exact piece of code the Dev team used in their tests. So to address this issue the container image needs to be immutable: once it&rsquo;s built, it&rsquo;s not going to be changed, ever. And the same image will be used for testing, QA, beta, preview, presales-demo, whatever environment you need to deploy the app to.</p>
<h4 id="building-it">Building it</h4>
<p>Docker has been around for a few years now, it&rsquo;s mature and stable, but ask anyone using it if they&rsquo;d allow images built on development workstation to run in production: not gonna happen! The artifact that will serve production traffic will pass through the CI/CD pipelines and pushed to the registry, this is the way of shipping containers. &ldquo;That&rsquo;s easy&rdquo;, you&rsquo;ll say, &ldquo;I&rsquo;ll stick my Dockerfile in the repo and let the build system do the magic!&rdquo;, but that&rsquo;s not the whole picture: there are lower layers to pull, tests to be run and <em>only after they succeed</em> you can build the container. So who is going to maintain all of this configurations? Can we store them into the repo too? Yes! With GCB you can write a declarative multi-step workflow that will compile, test and package the code in a container; the container will get immediately pushed to the Google Container Registry too, so it&rsquo;s ready to be consumed (maybe Kubernetes on GKE?).</p>
<h4 id="a-simple-application">A simple application</h4>
<p>There is quite a good number of examples in the <a href="https://github.com/GoogleCloudPlatform/cloud-builders" title="GCB on Github">cloud builder repository</a> but I&rsquo;d like to create a fresh one with Golang: a random number generator. The app will serve a random integer via HTTP, and you can see the code is <a href="https://github.com/inge4pres/blog/blob/master/getting-started-with-google-cloud-builder/main.go">very straightforward</a>.
Now I want to build a container to run into GCP with confidence so that every time I make a build I will have a new container image tagged with the version and ready to roll it out.</p>
<h4 id="using-gcb">Using GCB</h4>
<p>All builds in GCB happen in a container, right now the only engine supported is Docker but more are going to be added. You can leverage Google pre-baked builders or use your own images as builders, in the example I am using Google&rsquo;s <code>golang-project</code> image to compile and <code>docker</code> to build the final docker image and push it to registry. Note how some environment variables are injected to the container, like <code>PROJECT_ID</code> is your GCP running project as configured via</p>
<pre tabindex="0"><code>gcloud auth login
gcloud config set project your-gcp-project
</code></pre><h5 id="_side-note-for-gophers_"><em>Side note for gophers</em></h5>
<p>The <code>golang-project</code> image does some checks at setup to determine the workspace structure: there need to be a <code>./src</code> folder or <code>GOPATH</code> must be passed, or the simplest way is to <a href="https://github.com/inge4pres/blog/blob/master/getting-started-with-google-cloud-builder/main.go#L1">insert a comment next to <code>package main</code> in <code>main.go</code></a></p>
<h4 id="running-the-build">Running the build</h4>
<p>It&rsquo;s as easy as executing</p>
<pre tabindex="0"><code>gcloud container builds submit --config cloudbuild.yaml .
</code></pre><p>in the root of your project.</p>
<p>See it in action!</p>
<!-- raw HTML omitted -->
<p>As you can see the current folder (<code>.</code> as last parameter) is compressed and shipped to a Cloud Storage random location, then GCB starts the steps listed in the configuration YAML file, running step by step the containers with their arguments.</p>
<h4 id="conclusion">Conclusion</h4>
<p>GCB is fast and very easy to use but for what I&rsquo;ve been able to test is bound to GCP right now, so if you are willing to deliver a service from Google Cloud and your application is containerized or <em>&ldquo;cloud native&rdquo;</em> you have a lightweight build system ready to go, but if you have a private registry or other integrations to do, GCB might still be a too small niche.</p>
<p>I&rsquo;ll make more tests and try to hack a bit GCB in the future so stay tuned!</p>

</article>

<article class="sm:mx-12 mb-16 prose lg:prose-lg">
  <h1><a href="https://inge.4pr.es/post/2015-08-02-golang-message-queue-a-simple-tcp-message-bus/">Golang Message Queue: a simple TCP message bus</a></h1>
  <p><strong>[TL;DR]</strong></p>
<p>I wrote a Pub/Sub message queue in <!-- raw HTML omitted -->Go<!-- raw HTML omitted -->, branch ‚Äúmaster‚Äù is stable but missing some interesting feature like distributed memory synchronization between nodes in a cluster and encryption. Code at</p>
<p><!-- raw HTML omitted --><a href="https://github.com/inge4pres/gmq">https://github.com/inge4pres/gmq</a><!-- raw HTML omitted --></p>
<p>Being a cloud system engineer, my work is to design and implement distributed systems: one of the key principles in designing such architectures is <em>decoupling</em>, which means ensuring the many parts composing the system are able to share informations and complete a sequence of operations without being tied together. You can read more about cloud architectures and decoupling here.</p>
<p>One of the most common scenario in a cloud application is a series of asynchronous operations executed by many nodes on different layers: for example a front end server tier receiving¬† files and a backend server tier doing analysis on them; a good practice is to have a message queue between the two serving as an orchestration component. Each web server node will post a message in the queue for every files received, each backend node will consume a message from the queue to complete his operations on the files. In this way the two tiers are independent one from each other: in case of backend failure or over-capacity, the web servers will keep receiving files and storing message in the queue. If the two operations where done synchronously, the backend failure would stop the whole system to work.</p>
<p>A lot of <em>off-the-shelf</em> message queue software is already available, but I felt like writing my own would give me a good point of view on system programming with Go, so I wrote it, and the result is pretty awesome too. In a few days I was able to have a configurable message queue storing messages in memory, on filesystem or database (MySQL); communication is based on JSON via TCP, and the server can be configured to support a maximum number of queues, a maximum message length and queue capacity: combination of the configured parameters will have performance effects on the single node.</p>
<p>The roadmap of ‚Äúdeveloment‚Äù branch is:</p>
<ul>
<li>adding cluster mode</li>
<li>adding memory synchronization in cluster mode</li>
<li>adding encryption: TLS over TCP</li>
<li>adding client authentication</li>
</ul>
<p>As you may have guessed from the above list, security of GMQ is not implemented at the moment, be careful!</p>
<p>Feel free to try it out and give suggestions!</p>
<p>Cheers üòÄ</p>

</article>
 
    </main><footer class="w-full text-center p-4 text-xs text-gray-400">
  <p>
    Built with
    <a
      href="https://gohugo.io"
      target="_blank"
      rel="noopener noreferrer"
      class="underline hover:text-blue-800 dark:hover:text-blue-300"
      >Hugo</a
    >
    and
    <a
      href="https://github.com/apvarun/showfolio-hugo-theme"
      target="_blank"
      rel="noopener noreferrer"
      class="underline hover:text-blue-800 dark:hover:text-blue-300"
      >Showfolio</a
    >
  </p>
</footer>

</body>
</html>
